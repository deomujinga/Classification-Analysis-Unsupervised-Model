{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a74b1f9",
   "metadata": {},
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "<br><h1>Assignment 2</h1>\n",
    "Deo Mujinga<br>\n",
    "Hult International Business School<br><br><br>\n",
    "\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "61886fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas            as pd                       # data science essentials\n",
    "import matplotlib.pyplot as plt                      # data visualization\n",
    "import seaborn           as sns                      # enhanced data viz\n",
    "from sklearn.model_selection import train_test_split # train-test split\n",
    "from sklearn.linear_model import LogisticRegression  # logistic regression\n",
    "import statsmodels.formula.api as smf                # logistic regression\n",
    "from sklearn.metrics import confusion_matrix         # confusion matrix\n",
    "from sklearn.metrics import roc_auc_score            # auc score\n",
    "from sklearn.neighbors import KNeighborsClassifier   # KNN for classification\n",
    "from sklearn.neighbors import KNeighborsRegressor    # KNN for regression\n",
    "from sklearn.preprocessing import StandardScaler     # standard scaler\n",
    "from sklearn.tree import DecisionTreeClassifier      # classification trees\n",
    "from sklearn.tree import plot_tree                   # tree plots\n",
    "import gender_guesser.detector as gender             # Guess gender\n",
    "from sklearn.model_selection import RandomizedSearchCV     # hyperparameter tuning\n",
    "from sklearn.metrics import make_scorer              # customizable scorer\n",
    "\n",
    "\n",
    "# loading data\n",
    "GOT = pd.read_excel(io =  \"../__datasets/GOT_character_predictions.xlsx\")\n",
    "\n",
    "\n",
    "# setting pandas print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "\n",
    "# displaying the head of the dataset\n",
    "# GOT.head(n = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b555400c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Size of original data set:\n",
      "--------------------------\n",
      "Observations: 1946\n",
      "Features:     25\n",
      "\n",
      "\n",
      "Features with missing values before imputation: \n",
      "----------------------------------------------\n",
      "S.No                          False\n",
      "name                          False\n",
      "title                          True\n",
      "culture                        True\n",
      "dateOfBirth                    True\n",
      "mother                         True\n",
      "father                         True\n",
      "heir                           True\n",
      "house                          True\n",
      "spouse                         True\n",
      "book1_A_Game_Of_Thrones       False\n",
      "book2_A_Clash_Of_Kings        False\n",
      "book3_A_Storm_Of_Swords       False\n",
      "book4_A_Feast_For_Crows       False\n",
      "book5_A_Dance_with_Dragons    False\n",
      "isAliveMother                  True\n",
      "isAliveFather                  True\n",
      "isAliveHeir                    True\n",
      "isAliveSpouse                  True\n",
      "isMarried                     False\n",
      "isNoble                       False\n",
      "age                            True\n",
      "numDeadRelations              False\n",
      "popularity                    False\n",
      "isAlive                       False\n",
      "dtype: bool\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check features and Observations\n",
    "print(f\"\"\"\n",
    "Size of original data set:\n",
    "--------------------------\n",
    "Observations: {GOT.shape[0]}\n",
    "Features:     {GOT.shape[1]}\n",
    "\"\"\")\n",
    "\n",
    "# Check for NAN in features\n",
    "print(f\"\"\"\n",
    "Features with missing values before imputation: \n",
    "----------------------------------------------\n",
    "{GOT.isna().any()}\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "#Keep Original data set intact (This could be referred to at a later stage for data integrity check)\n",
    "GOT_Original = GOT.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c691063e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of columns before imputation: \n",
      "------------------------------------\n",
      "#25\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Count the number of columns working with before imputation \n",
    "print(f\"\"\"\n",
    "Number of columns before imputation: \n",
    "------------------------------------\n",
    "#{len(GOT.columns)}\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "#Flag missing values\n",
    "GOT[\"m_title\"] = GOT[\"title\"]\n",
    "GOT[\"m_culture\"] = GOT[\"culture\"]\n",
    "GOT[\"m_dateOfBirth\"] = GOT[\"dateOfBirth\"]\n",
    "GOT[\"m_mother\"] = GOT[\"mother\"]\n",
    "GOT[\"m_father\"] = GOT[\"father\"]\n",
    "GOT[\"m_heir\"] = GOT[\"heir\"]\n",
    "GOT[\"m_house\"] = GOT[\"house\"]\n",
    "GOT[\"m_spouse\"] = GOT[\"spouse\"]\n",
    "GOT[\"m_isAliveMother\"] = GOT[\"isAliveMother\"]\n",
    "GOT[\"m_isAliveFather\"] = GOT[\"isAliveFather\"]\n",
    "GOT[\"m_isAliveHeir\"] = GOT[\"isAliveHeir\"]\n",
    "GOT[\"m_isAliveSpouse\"] = GOT[\"isAliveSpouse\"]\n",
    "GOT[\"m_age\"] = GOT[\"age\"]\n",
    "\n",
    "#Impute\n",
    "GOT[[\"m_title\"]] = GOT[[\"m_title\"]].fillna(value = \"NoTitle\")\n",
    "GOT[[\"m_culture\"]] = GOT[[\"culture\"]].fillna(value = \"Unknown\")\n",
    "GOT[[\"m_dateOfBirth\"]] = GOT[[\"m_dateOfBirth\"]].fillna(value = GOT.dateOfBirth.mode()[0])\n",
    "GOT[[\"m_mother\"]] = GOT[[\"m_mother\"]].fillna(value = \"Unknown\")\n",
    "GOT[[\"m_father\"]] = GOT[[\"m_father\"]].fillna(value = \"Unknown\")\n",
    "GOT[[\"m_heir\"]] = GOT[[\"m_heir\"]].fillna(value = \"Unknown\")\n",
    "GOT[[\"m_house\"]] = GOT[[\"m_house\"]].fillna(value = \"Unknown\")\n",
    "GOT[[\"m_spouse\"]] = GOT[[\"m_spouse\"]].fillna(value = \"Unknown\")\n",
    "GOT[[\"m_isAliveMother\"]] = GOT[[\"m_isAliveMother\"]].fillna(value = GOT.isAliveMother.mode()[0])\n",
    "GOT[[\"m_isAliveFather\"]] = GOT[[\"m_isAliveFather\"]].fillna(value = GOT.isAliveFather.mode()[0])\n",
    "GOT[[\"m_isAliveHeir\"]] = GOT[[\"m_isAliveHeir\"]].fillna(value = GOT.isAliveHeir.mode()[0])\n",
    "GOT[[\"m_isAliveSpouse\"]] = GOT[[\"m_isAliveSpouse\"]].fillna(value = GOT.isAliveSpouse.mode()[0])\n",
    "GOT[[\"m_age\"]] = GOT[[\"m_age\"]].fillna(value = GOT.age.mode()[0])\n",
    "\n",
    "\n",
    "#Drop Original Columns\n",
    "GOT = GOT.drop(columns=[\"title\", \"culture\", \"dateOfBirth\", \"mother\", \"father\", \"heir\", \"house\", \"spouse\",\"isAliveMother\", \"isAliveFather\", \"isAliveHeir\", \"isAliveSpouse\", \"age\"])\n",
    "\n",
    "GOT_name = GOT[\"name\"]\n",
    "\n",
    "#Introduce gender column\n",
    "GOT[[\"guessed_gender\"]] = \"\"\n",
    "\n",
    "for idx, row in GOT.iterrows():\n",
    "\n",
    "        if(\" \" in GOT.name[idx]): #Split if the name contains a space\n",
    "        \n",
    "            name_ = GOT.name[idx].split(None, 1)[1] #Guess the gender by the first name \n",
    "            \n",
    "            gender_ = gender.Detector().get_gender(name_).capitalize()\n",
    "            \n",
    "            if (gender_ == \"\"):\n",
    "                gender_ = \"Unknown\"\n",
    "            \n",
    "            GOT.loc[idx,\"guessed_gender\"] = gender_\n",
    "            \n",
    "            #print(f\"\"\" \\\"{gender_}\\\"\"\"\" )\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c90b9e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of columns after imputation(Includes gender feature): \n",
      "------------------------------------------------------------\n",
      "#26\n",
      "\n",
      "\n",
      "\n",
      "Features with missing values after imputation: \n",
      "----------------------------------------------\n",
      "S.No                          False\n",
      "name                          False\n",
      "book1_A_Game_Of_Thrones       False\n",
      "book2_A_Clash_Of_Kings        False\n",
      "book3_A_Storm_Of_Swords       False\n",
      "book4_A_Feast_For_Crows       False\n",
      "book5_A_Dance_with_Dragons    False\n",
      "isMarried                     False\n",
      "isNoble                       False\n",
      "numDeadRelations              False\n",
      "popularity                    False\n",
      "isAlive                       False\n",
      "m_title                       False\n",
      "m_culture                     False\n",
      "m_dateOfBirth                 False\n",
      "m_mother                      False\n",
      "m_father                      False\n",
      "m_heir                        False\n",
      "m_house                       False\n",
      "m_spouse                      False\n",
      "m_isAliveMother               False\n",
      "m_isAliveFather               False\n",
      "m_isAliveHeir                 False\n",
      "m_isAliveSpouse               False\n",
      "m_age                         False\n",
      "guessed_gender                False\n",
      "dtype: bool\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Count the number of columns working with before imputation \n",
    "print(f\"\"\"\n",
    "Number of columns after imputation(Includes gender feature): \n",
    "------------------------------------------------------------\n",
    "#{len(GOT.columns)}\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "# Check for NAN in features\n",
    "print(f\"\"\"\n",
    "Features with missing values after imputation: \n",
    "----------------------------------------------\n",
    "{GOT.isna().any()}\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51bf3969",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#TOTALLY RAN OUT OF TIME BEFORECOMPLETING THE SUBSETTING INTO CATEGORIES AND GET DUMMIES FROM THEM.\n",
    "#HOUSE, TITLE, FATHER AND MOTHER WOULD HAVE BEEN CATEGORIZED\n",
    "\n",
    "#Create a category for cultures.\n",
    "#Through research the categories obtained are the ones on which information could be found.\n",
    "#Cultures on which information could not be found are then slotted in as Unknown\n",
    "\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Rivermen','m_culture'] ='Westeros'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'FreeFolk','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Ghiscari','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Freefolk','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Westerman','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Norvoshi','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Westermen','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Valemen','m_culture'] ='Westeros'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Northernmountainclans','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Wildling','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Westerlands','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Rhoynar','m_culture'] ='Westeros'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Astapor','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Dornish','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Northmen','m_culture'] ='North'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Valemountainclans','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Ironmen','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Qarth','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'FirstMen','m_culture'] ='Westeros'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'ironborn','m_culture'] ='Westeros'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Myrish','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Andals','m_culture'] ='Westeros'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Dorne','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'SummerIslands','m_culture'] ='Westeros'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Meereen','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Reachmen','m_culture'] ='Westeros'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Valyrian','m_culture'] ='Essos'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'SummerIsles','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Reach','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Qartheen','m_culture'] ='Essos'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Lyseni','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Meereenese','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Ghiscaricari','m_culture'] ='Essos'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Lhazareen','m_culture'] ='North'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Vale','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Pentoshi','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Asshai','m_culture'] ='Essos'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Norvos','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == '\"Asshaii\"','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Ironborn','m_culture'] ='Westeros'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Braavosi','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Tyroshi','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Lysene','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'northmen','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Andal','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Braavos','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Dornishmen','m_culture'] ='Essos'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Crannogmen','m_culture'] ='North'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'freefolk','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Riverlands','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Stormlander','m_culture'] ='Westeros'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Ibbenese','m_culture'] ='Essos'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Dothraki','m_culture'] ='Essos'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Lhazarene','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'westermen','m_culture'] ='Westeros'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Qohor','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Astapori','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Stormlands','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Sistermen','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'SummerIslander','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Naathi','m_culture'] ='Westeros'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Wildlings','m_culture'] ='Westeros'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'TheReach','m_culture'] ='Unknown'\n",
    "# GOT.loc[GOT[\"m_culture\"]  == 'Westeros','m_culture'] ='Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20a9aece",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Create Category\n",
    "GOT[[\"cat_m_culture\"]] = GOT[[\"m_culture\"]]\n",
    "GOT[[\"cat_m_house\"]] = GOT[[\"m_house\"]]\n",
    "GOT[[\"cat_m_mother\"]] = GOT[[\"m_mother\"]]\n",
    "GOT[[\"cat_m_father\"]] = GOT[[\"m_father\"]]\n",
    "GOT[[\"cat_m_title\"]] = GOT[[\"m_title\"]]\n",
    "\n",
    "#Convert the features into categorical values\n",
    "GOT[\"cat_m_culture\"] = GOT[\"cat_m_culture\"].astype(\"category\")\n",
    "GOT[\"cat_m_house\"] = GOT[\"cat_m_house\"].astype(\"category\")\n",
    "GOT[\"cat_m_mother\"] = GOT[\"cat_m_mother\"].astype(\"category\")\n",
    "GOT[\"cat_m_father\"] = GOT[\"cat_m_father\"].astype(\"category\")\n",
    "GOT[\"cat_m_title\"] = GOT[\"cat_m_title\"].astype(\"category\")\n",
    "\n",
    "#Get the categorical values\n",
    "GOT[\"cat_m_culture\"] = GOT[\"cat_m_culture\"].cat.codes\n",
    "GOT[\"cat_m_house\"] = GOT[\"cat_m_house\"].cat.codes\n",
    "GOT[\"cat_m_mother\"] = GOT[\"cat_m_mother\"].cat.codes\n",
    "GOT[\"cat_m_father\"] = GOT[\"cat_m_father\"].cat.codes\n",
    "GOT[\"cat_m_title\"] = GOT[\"cat_m_title\"].cat.codes\n",
    "\n",
    "#Convert unique values to binary\n",
    "GOT.loc[GOT[\"guessed_gender\"] == \"Unknown\", \"guessed_gender\"] = \"Male\"\n",
    "GOT.loc[GOT[\"guessed_gender\"] == \"Mostly_male\", \"guessed_gender\"] = \"Male\"\n",
    "GOT.loc[GOT[\"guessed_gender\"] == \"Mostly_female\", \"guessed_gender\"] = \"Female\"\n",
    "GOT.loc[GOT[\"guessed_gender\"] == \"Andy\", \"guessed_gender\"] = \"Male\"\n",
    "GOT.loc[GOT[\"guessed_gender\"] == \"\", \"guessed_gender\"] = \"Male\"\n",
    "\n",
    "\n",
    "#Convert to guessed gender to categorical\n",
    "GOT[\"guessed_gender\"] = GOT[\"guessed_gender\"].astype(\"category\")\n",
    "\n",
    "#Get the categeroies from the converted features\n",
    "GOT[\"isMale_guessed_gender\"] = GOT[\"guessed_gender\"].cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb23a8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop uncontrollable features\n",
    "GOT = GOT.drop(\"name\", axis = 1)\n",
    "GOT = GOT.drop(\"m_heir\", axis = 1)\n",
    "GOT = GOT.drop(\"m_culture\", axis = 1)\n",
    "GOT = GOT.drop(\"m_mother\", axis = 1)\n",
    "GOT = GOT.drop(\"m_father\", axis = 1)\n",
    "GOT = GOT.drop(\"m_house\", axis = 1)\n",
    "GOT = GOT.drop(\"m_spouse\", axis = 1)\n",
    "GOT = GOT.drop(\"m_title\", axis = 1)\n",
    "GOT = GOT.drop(\"guessed_gender\", axis = 1)\n",
    "\n",
    "\n",
    "#Drop missing and categorized variables\n",
    "# GOT.head(n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2582e0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg Training ACCURACY: 0.7836\n",
      "LogReg Testing  ACCURACY: 0.8154\n",
      "LogReg Train-Test Gap   : 0.0318\n",
      "AUC Score        : 0.6531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deomu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#declaring explanatory variables\n",
    "GOT_data = GOT.drop(\"isAlive\", axis = 1)\n",
    "\n",
    "# declaring response variable\n",
    "GOT_target = GOT.loc[:, \"isAlive\"] \n",
    "\n",
    "\n",
    "# this is the exact code we were using before\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            GOT_data,\n",
    "            GOT_target,\n",
    "            random_state = 219,\n",
    "            test_size    = 0.10,\n",
    "            stratify     = GOT_target)\n",
    "\n",
    "\n",
    "# INSTANTIATING a logistic regression model\n",
    "logreg = LogisticRegression(solver = 'lbfgs',\n",
    "                            C = 3,\n",
    "                            random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "logreg_fit = logreg.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "logreg_pred = logreg_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('LogReg Training ACCURACY:', logreg_fit.score(x_train, y_train).round(4))\n",
    "print('LogReg Testing  ACCURACY:', logreg_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "# saving scoring data for future use\n",
    "logreg_train_score = logreg_fit.score(x_train, y_train).round(4) # accuracy\n",
    "logreg_test_score  = logreg_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('LogReg Train-Test Gap   :', abs(logreg_train_score - logreg_test_score).round(4))\n",
    "logreg_test_gap = abs(logreg_train_score - logreg_test_score).round(4)\n",
    "\n",
    "# SCORING with AUC\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = logreg_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3741a164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.8281\n",
      "Testing  ACCURACY: 0.841\n",
      "AUC Score        : 0.7621\n"
     ]
    }
   ],
   "source": [
    "#This section is to build the decision tree classifier\n",
    "# INSTANTIATING a classification tree object\n",
    "\n",
    "pruned_tree = DecisionTreeClassifier(max_depth = 8,\n",
    "                                     min_samples_leaf = 25,\n",
    "                                     random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "pruned_tree_fit  = pruned_tree.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "pruned_tree_pred = pruned_tree_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Training ACCURACY:', pruned_tree_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', pruned_tree_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test, y_score = pruned_tree_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "pruned_tree_train_score = pruned_tree_fit.score(x_train, y_train).round(4) # accuracy\n",
    "pruned_tree_test_score  = pruned_tree_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving auc score\n",
    "pruned_tree_auc_score   = roc_auc_score(y_true  = y_test, y_score = pruned_tree_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c2f018f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 16  34]\n",
      " [  2 143]]\n",
      "\n",
      "True Negatives : 16\n",
      "False Positives: 34\n",
      "False Negatives: 2\n",
      "True Positives : 143\n",
      "\n",
      "\n",
      "True Negatives : 30\n",
      "False Positives: 20\n",
      "False Negatives: 11\n",
      "True Positives : 134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating a confusion matrix\n",
    "print(confusion_matrix(y_true = y_test,y_pred = logreg_pred))\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "logreg_tn, \\\n",
    "logreg_fp, \\\n",
    "logreg_fn, \\\n",
    "logreg_tp = confusion_matrix(y_true = y_test, y_pred = logreg_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {logreg_tn}\n",
    "False Positives: {logreg_fp}\n",
    "False Negatives: {logreg_fn}\n",
    "True Positives : {logreg_tp}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "pruned_tree_tn, \\\n",
    "pruned_tree_fp, \\\n",
    "pruned_tree_fn, \\\n",
    "pruned_tree_tp = confusion_matrix(y_true = y_test, y_pred = pruned_tree_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {pruned_tree_tn}\n",
    "False Positives: {pruned_tree_fp}\n",
    "False Negatives: {pruned_tree_fn}\n",
    "True Positives : {pruned_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ebd73151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.8715\n",
      "Testing ACCURACY : 0.8667\n",
      "AUC Score        : 0.7728\n",
      "\n",
      "True Negatives : 29\n",
      "False Positives: 21\n",
      "False Negatives: 5\n",
      "True Positives : 140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Here we are building the GBM Model.\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier # gbm\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "full_gbm_default = GradientBoostingClassifier(loss          = 'deviance',\n",
    "                                              learning_rate = 0.1,\n",
    "                                              n_estimators  = 100,\n",
    "                                              criterion     = 'friedman_mse',\n",
    "                                              max_depth     = 3,\n",
    "                                              warm_start    = False,\n",
    "                                              random_state  = 219)\n",
    "\n",
    "\n",
    "# FIT step is needed as we are not using .best_estimator\n",
    "full_gbm_default_fit = full_gbm_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "full_gbm_default_pred = full_gbm_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', full_gbm_default_fit.score(x_train, y_train).round(4))\n",
    "print('Testing ACCURACY :', full_gbm_default_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,y_score = full_gbm_default_pred).round(4))\n",
    "\n",
    "# saving scoring data for future use\n",
    "GBM_train_score = full_gbm_default_fit.score(x_train, y_train).round(4) # accuracy\n",
    "GBM_test_score  = full_gbm_default_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "# saving auc score\n",
    "GBM_auc_score   = roc_auc_score(y_true  = y_test,y_score = full_gbm_default_pred).round(4) # auc\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "full_gbm_default_tn, \\\n",
    "full_gbm_default_fp, \\\n",
    "full_gbm_default_fn, \\\n",
    "full_gbm_default_tp = confusion_matrix(y_true = y_test, y_pred = full_gbm_default_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {full_gbm_default_tn}\n",
    "False Positives: {full_gbm_default_fp}\n",
    "False Negatives: {full_gbm_default_fn}\n",
    "True Positives : {full_gbm_default_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dff14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on the model above tuning GBM is the best bet for a better model\n",
    "#Here we are tuning the GBM model\n",
    "#THIS PIECE OF CODE IS COMMENTED OUT DUE TO THE LENGTHY TIME IT TAKES TO RUN\n",
    "\n",
    "# from sklearn.model_selection import RandomizedSearchCV # hyperparameter tuning\n",
    "# from sklearn.metrics import make_scorer                # customizable scorer\n",
    "\n",
    "# # declaring a hyperparameter space\n",
    "# learn_range        = np.arange(0.02, 2.9, 0.3)\n",
    "# estimator_range    = np.arange(75, 750, 25)\n",
    "# depth_range        = np.arange(2, 11, 2)\n",
    "# warm_start_range   = [True, False]\n",
    "\n",
    "# # creating a hyperparameter grid\n",
    "# param_grid = {'learning_rate' : learn_range,\n",
    "#               'max_depth'     : depth_range,\n",
    "#               'n_estimators'  : estimator_range,\n",
    "#               'warm_start'    : warm_start_range}\n",
    "\n",
    "\n",
    "# # INSTANTIATING the model object without hyperparameters\n",
    "# full_gbm_grid = GradientBoostingClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# # GridSearchCV object\n",
    "# full_gbm_cv = RandomizedSearchCV(estimator     = full_gbm_grid,\n",
    "#                            param_distributions = param_grid,\n",
    "#                            cv                  = 3,\n",
    "#                            n_iter              = 500,\n",
    "#                            random_state        = 219,\n",
    "#                            scoring             = make_scorer(roc_auc_score,\n",
    "#                                                  needs_threshold = False))\n",
    "\n",
    "\n",
    "# # FITTING to the FULL DATASET (due to cross-validation)\n",
    "# full_gbm_cv.fit(GOT_data, GOT_target)\n",
    "\n",
    "\n",
    "# # PREDICT step is not needed\n",
    "\n",
    "\n",
    "# # printing the optimal parameters and best score\n",
    "# print(\"Tuned Parameters  :\", full_gbm_cv.best_params_)\n",
    "# print(\"Tuned Training AUC:\", full_gbm_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93b06ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Parameters  : {'splitter': 'best', 'min_samples_leaf': 185, 'max_depth': 3.1, 'criterion': 'entropy'}\n",
      "Tuned Training AUC: 0.665\n"
     ]
    }
   ],
   "source": [
    "#Here we are now tuning the decision tree model\n",
    "#THIS PIECE OF CODE IS COMMENTED OUT DUE TO THE LENGTHY TIME IT TAKES TO RUN\n",
    "\n",
    "# from sklearn.model_selection import RandomizedSearchCV     # hyperparameter tuning\n",
    "# from sklearn.metrics import make_scorer              # customizable scorer\n",
    "\n",
    "# # declaring a hyperparameter space\n",
    "# criterion_range = ['gini', 'entropy']\n",
    "# splitter_range  = ['best', 'random']\n",
    "# depth_range     = np.arange(0.1, 8, 1)\n",
    "# leaf_range      = np.arange(1, 1000, 1)\n",
    "\n",
    "\n",
    "# # creating a hyperparameter grid\n",
    "# param_grid = {'criterion'        : criterion_range,\n",
    "#               'splitter'         : splitter_range,\n",
    "#               'max_depth'        : depth_range,\n",
    "#               'min_samples_leaf' : leaf_range}\n",
    "\n",
    "\n",
    "# # INSTANTIATING the model object without hyperparameters\n",
    "# tuned_tree = DecisionTreeClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# # RandomizedSearchCV object\n",
    "# tuned_tree_cv = RandomizedSearchCV(estimator             = tuned_tree,\n",
    "#                                    param_distributions   = param_grid,\n",
    "#                                    cv                    = 3,\n",
    "#                                    n_iter                = 1000,\n",
    "#                                    random_state          = 219,\n",
    "#                                    scoring = make_scorer(roc_auc_score,\n",
    "#                                              needs_threshold = False))\n",
    "\n",
    "\n",
    "# # FITTING to the FULL DATASET (due to cross-validation)\n",
    "# tuned_tree_cv.fit(GOT_data, GOT_target)\n",
    "\n",
    "\n",
    "# # PREDICT step is not needed\n",
    "\n",
    "\n",
    "# # printing the optimal parameters and best score\n",
    "# print(\"Tuned Parameters  :\", tuned_tree_cv.best_params_)\n",
    "\n",
    "\n",
    "# print(\"Tuned Training AUC:\", tuned_tree_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd98ae8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This section is to build a function that will be called by the KNN algorithm\n",
    "#The function returns the optimal number of neighbors, which ultimately is used by the calling algorithm\n",
    "\n",
    "def optimal_neighbors(x_data,\n",
    "                      y_data,\n",
    "                      standardize = True,\n",
    "                      pct_test=0.10,\n",
    "                      seed=219,\n",
    "                      response_type='reg',\n",
    "                      max_neighbors=20,\n",
    "                      show_viz=True):\n",
    "    \"\"\"\n",
    "Exhaustively compute training and testing results for KNN across\n",
    "[1, max_neighbors]. Outputs the maximum test score and (by default) a\n",
    "visualization of the results.\n",
    "PARAMETERS\n",
    "----------\n",
    "x_data        : explanatory variable data\n",
    "y_data        : response variable\n",
    "standardize   : whether or not to standardize the x data, default True\n",
    "pct_test      : test size for training and validation from (0,1), default 0.25\n",
    "seed          : random seed to be used in algorithm, default 219\n",
    "response_type : type of neighbors algorithm to use, default 'reg'\n",
    "    Use 'reg' for regression (KNeighborsRegressor)\n",
    "    Use 'class' for classification (KNeighborsClassifier)\n",
    "max_neighbors : maximum number of neighbors in exhaustive search, default 20\n",
    "show_viz      : display or surpress k-neigbors visualization, default True\n",
    "\"\"\"    \n",
    "    \n",
    "    \n",
    "    if standardize == True:\n",
    "        # optionally standardizing x_data\n",
    "        scaler             = StandardScaler()\n",
    "        scaler.fit(x_data)\n",
    "        x_scaled           = scaler.transform(x_data)\n",
    "        x_scaled_df        = pd.DataFrame(x_scaled)\n",
    "        x_data             = x_scaled_df\n",
    "\n",
    "\n",
    "\n",
    "    # train-test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data,\n",
    "                                                        y_data,\n",
    "                                                        test_size = pct_test,\n",
    "                                                        random_state = seed)\n",
    "\n",
    "\n",
    "    # creating lists for training set accuracy and test set accuracy\n",
    "    training_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    \n",
    "    # setting neighbor range\n",
    "    neighbors_settings = range(1, max_neighbors + 1)\n",
    "\n",
    "\n",
    "    for n_neighbors in neighbors_settings:\n",
    "        # building the model based on response variable type\n",
    "        if response_type == 'reg':\n",
    "            clf = KNeighborsRegressor(n_neighbors = n_neighbors)\n",
    "            clf.fit(x_train, y_train)\n",
    "            \n",
    "        elif response_type == 'class':\n",
    "            clf = KNeighborsClassifier(n_neighbors = n_neighbors)\n",
    "            clf.fit(x_train, y_train)            \n",
    "            \n",
    "        else:\n",
    "            print(\"Error: response_type must be 'reg' or 'class'\")\n",
    "        \n",
    "        \n",
    "        # recording the training set accuracy\n",
    "        training_accuracy.append(clf.score(x_train, y_train))\n",
    "    \n",
    "        # recording the generalization accuracy\n",
    "        test_accuracy.append(clf.score(x_test, y_test))\n",
    "\n",
    "\n",
    "    # optionally displaying visualization\n",
    "    #No need to plot\n",
    "    \n",
    "#     if show_viz == True:\n",
    "#         # plotting the visualization\n",
    "#         fig, ax = plt.subplots(figsize=(12,8))\n",
    "#         plt.plot(neighbors_settings, training_accuracy, label = \"training accuracy\")\n",
    "#         plt.plot(neighbors_settings, test_accuracy, label = \"test accuracy\")\n",
    "#         plt.ylabel(\"Accuracy\")\n",
    "#         plt.xlabel(\"n_neighbors\")\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "    \n",
    "    \n",
    "    # returning optimal number of neighbors\n",
    "    print(f\"The optimal number of neighbors is: {test_accuracy.index(max(test_accuracy))+1}\")\n",
    "    return test_accuracy.index(max(test_accuracy))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c2a0ebc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of neighbors is: 9\n",
      "Training ACCURACY: 0.7807\n",
      "Testing  ACCURACY: 0.7436\n",
      "AUC Score        : 0.5459\n",
      "\n",
      "True Negatives : 30\n",
      "False Positives: 20\n",
      "False Negatives: 11\n",
      "True Positives : 134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Run the KNN Model against the dataset and assess results\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier   # KNN for classification\n",
    "from sklearn.neighbors import KNeighborsRegressor    # KNN for regression\n",
    "\n",
    "# determining the optimal number of neighbors\n",
    "opt_neighbors = optimal_neighbors(x_data        = GOT_data,\n",
    "                                  y_data        = GOT_target,\n",
    "                                  response_type = 'class')\n",
    "\n",
    "# INSTANTIATING StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# FITTING the data\n",
    "scaler.fit(GOT_data)\n",
    "\n",
    "\n",
    "# TRANSFORMING the data\n",
    "x_scaled     = scaler.transform(GOT_data)\n",
    "\n",
    "\n",
    "# converting to a DataFrame\n",
    "x_scaled_df  = pd.DataFrame(x_scaled) \n",
    "\n",
    "\n",
    "# # train-test split with the scaled data\n",
    "# x_train_scaled, x_test_scaled, y_train_scaled, y_test_scaled = train_test_split(\n",
    "#             x_scaled_df,\n",
    "#             titanic_target,\n",
    "#             random_state = 219,\n",
    "#             test_size    = 0.25,\n",
    "#             stratify     = titanic_target)\n",
    "\n",
    "\n",
    "# INSTANTIATING a KNN classification model with optimal neighbors\n",
    "knn_opt = KNeighborsClassifier(n_neighbors = opt_neighbors)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "knn_fit = knn_opt.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "knn_pred = knn_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', knn_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', knn_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = knn_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data\n",
    "knn_train_score = knn_fit.score(x_train, y_train).round(4)\n",
    "knn_test_score  = knn_fit.score(x_test, y_test).round(4)\n",
    "\n",
    "\n",
    "# saving AUC score\n",
    "knn_auc_score   = roc_auc_score(y_true  = y_test,y_score = knn_pred).round(4)\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "knn_tree_tn, \\\n",
    "knn_tree_fp, \\\n",
    "knn_tree_fn, \\\n",
    "knn_tree_tp = confusion_matrix(y_true = y_test, y_pred = knn_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {pruned_tree_tn}\n",
    "False Positives: {pruned_tree_fp}\n",
    "False Negatives: {pruned_tree_fn}\n",
    "True Positives : {pruned_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9f513e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model         AUC Score     Testing Score      Training Score     TN, FP, FN, TP   \n",
      "-----         ---------     --------------     --------------     -------------- \n",
      "KNN           0.5459           0.7436          0.7807           (30, 20, 11, 134)\n",
      "GBM(Final)**  0.7728           0.8667          0.8715           (29, 21, 5, 140)  \n",
      "\n",
      "Final model is indicated with **\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Final results\n",
    "\n",
    "\n",
    "# comparing results\n",
    "print(f\"\"\"\n",
    "Model         AUC Score     Testing Score      Training Score     TN, FP, FN, TP   \n",
    "-----         ---------     --------------     --------------     -------------- \n",
    "KNN           {knn_auc_score}           {knn_test_score}          {knn_train_score}           {pruned_tree_tn, pruned_tree_fp, pruned_tree_fn, pruned_tree_tp}\n",
    "GBM(Final)**  {GBM_auc_score}           {GBM_test_score}          {GBM_train_score}           {full_gbm_default_tn, full_gbm_default_fp, full_gbm_default_fn, full_gbm_default_tp}  \n",
    "\n",
    "Final model is indicated with **\n",
    "\"\"\")\n",
    "\n",
    "# # comparing results\n",
    "# print(f\"\"\"\n",
    "# Model         AUC Score                  Testing Score            Training Score              TN, FP, FN, TP   \n",
    "# -----         ---------                  --------------           --------------              -------------- \n",
    "# Logistic      {logreg_auc_score}        {logreg_test_score}       {logreg_train_score}        {logreg_tn, logreg_fp, logreg_fn, logreg_tp}\n",
    "# Pruned Tree   {pruned_tree_auc_score}   {pruned_tree_test_score}  {pruned_tree_train_score}   {pruned_tree_tn, pruned_tree_fp, pruned_tree_fn, pruned_tree_tp}\n",
    "# KNN           {knn_auc_score}           {knn_test_score}          {knn_train_score}           {pruned_tree_tn, pruned_tree_fp, pruned_tree_fn, pruned_tree_tp}\n",
    "# GBM(Final)**  {GBM_auc_score}           {GBM_test_score}          {GBM_train_score}           {full_gbm_default_tn, full_gbm_default_fp, full_gbm_default_fn, full_gbm_default_tp}  \n",
    "# Tuned tree    {tuned_tree_cv.best_score_.round(4)}NA                       NA                           NA\n",
    "\n",
    "# Final model is indicated with **\n",
    "# \"\"\")\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8931de6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
